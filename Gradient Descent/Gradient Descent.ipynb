{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression internally uses the concept of Gradient Descent to train the model\n",
    "\n",
    "##### We are doing the math behind .fit .intercept and .coeff-. We are just studying how this works. No need for code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put in very simple terms, Gradient Descent is a helper algorithm that aims to achieve the required optimal solution through trial and error method.\n",
    "\n",
    "So what is the problem and whats the solution?\n",
    "\n",
    "As an example, there is a Supervised machine learning model called the Linear Regression Model. In this model, we are given a specific dataset, say for example the rate at which a particular house sells as a function of its size.\n",
    "\n",
    "So, selling price = function(size)\n",
    "\n",
    "We plot the given dataset in a graph and as per this model, we try to draw the best possible straight line through this graph such that it covers most of the values given. By doing this, we can come up with a relatively accurate selling price for a house whose size is not there in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So the Aim of all this regression is to find the least Cost Function\n",
    "\n",
    "\n",
    "1) So we want to basically find the optimum value of m and c, so that we can have the least cost Function\n",
    "\n",
    "2) Cost Function is calculated as --  1/N(Summation of Y - (mx + c)^2\n",
    "\n",
    "3) Now this is in the form of a parabola and that we have to get to the tip of the parabola to get the minimum value\n",
    "\n",
    "4) So what we will do is input a random value of m and see if slope is positive or negetive. If its positive we will keep on reducing slope to get to minima and vice-versa for the other side of the slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula is attached as CostFunction_Formula PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Types of Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Batch GD - Basic GD in which we calculate slope of every line and then calculate 'm'\n",
    "\n",
    "2) Stiochastic GD - This calculates Slope of 1 line then 'm', on basis of that it calculates next line and keeps on changing 'm'. It is adaptive\n",
    "\n",
    "3) Mini Batch GD - This does only for a small batch of the entire batch.\n",
    "\n",
    "\n",
    "##### Usually Stiochastic is best GD. But again depends on factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done to make uniformity among features\n",
    "\n",
    "formula = (x-min/(max-min))\n",
    "\n",
    "better formula = make mean 0 and SD =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1.,-1.,2.],\n",
    "             [2.,0.,0.],\n",
    "             [0.,1.,-1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "scaler.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
